{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Unet\n",
    "from hyperparameters import *\n",
    "from utils import save_checkpoint, get_loaders, check_accuracy, save_predictions_as_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(loader, model, optimizer, loss_fn, scaler):\n",
    "    loop = tqdm(loader)\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data = data.float().to(device = DEVICE)\n",
    "        targets = targets.float().to(device = DEVICE)\n",
    "\n",
    "        # Forward\n",
    "        with torch.cuda.amp.autocast():\n",
    "            predictions = model(data)\n",
    "            loss = loss_fn(predictions, targets)\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Update Loop\n",
    "        loop.set_postfix(loss = loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.PILToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "    #transforms.Normalize(mean=[0.0, 0.0, 0.0], std=[1.0, 1.0, 1.0])\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "train_transform_gt = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.PILToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "    #transforms.Normalize(mean=[0.0], std=[1.0])\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.PILToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "    #transforms.Normalize(mean=[0.0, 0.0, 0.0], std=[1.0, 1.0, 1.0])\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "test_transform_gt = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.PILToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "    #transforms.Normalize(mean=[0.0], std=[1.0])\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Unet(in_channels = IN_CHANNELS, out_channels = OUT_CHANNELS).to(device = DEVICE)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "\n",
    "train_loader, test_loader = get_loaders(train_transform, test_transform, train_transform_gt, test_transform_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_fn(train_loader, model, optimizer, loss_fn, scaler)\n",
    "\n",
    "    checkpoint = {\n",
    "        \"state_dict\" : model.state_dict(),\n",
    "        \"optimizer\" : optimizer.state_dict()\n",
    "    }\n",
    "    \n",
    "    save_checkpoint(checkpoint)\n",
    "\n",
    "    check_accuracy(test_loader, model, device = DEVICE)\n",
    "\n",
    "    save_predictions_as_imgs(test_loader, model, folder = \"saved_images/\", device = DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_22776\\3715779838.py:2: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "c:\\Users\\andre\\miniconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_22776\\3815435854.py:9: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "c:\\Users\\andre\\miniconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:265: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "100%|██████████| 10/10 [00:58<00:00,  5.87s/it, loss=-550]  \n",
      "100%|██████████| 10/10 [00:59<00:00,  5.97s/it, loss=-4.16e+3]\n",
      "100%|██████████| 10/10 [00:59<00:00,  5.97s/it, loss=-6.57e+3]\n",
      "100%|██████████| 10/10 [01:00<00:00,  6.06s/it, loss=-9.05e+3]\n",
      "100%|██████████| 10/10 [01:04<00:00,  6.43s/it, loss=-6.21e+3]\n",
      "100%|██████████| 10/10 [01:01<00:00,  6.16s/it, loss=-8.45e+3]\n",
      "100%|██████████| 10/10 [01:01<00:00,  6.13s/it, loss=-7.86e+3]\n",
      "100%|██████████| 10/10 [00:59<00:00,  5.99s/it, loss=-6.66e+3]\n",
      "100%|██████████| 10/10 [01:00<00:00,  6.03s/it, loss=-7.99e+3]\n",
      "100%|██████████| 10/10 [00:59<00:00,  5.98s/it, loss=-9.01e+3]\n",
      "100%|██████████| 10/10 [00:59<00:00,  5.98s/it, loss=-9.35e+3]\n",
      "100%|██████████| 10/10 [01:00<00:00,  6.00s/it, loss=-8.69e+3]\n",
      "100%|██████████| 10/10 [00:59<00:00,  5.97s/it, loss=-1.19e+4]\n",
      "100%|██████████| 10/10 [00:59<00:00,  5.99s/it, loss=-1.01e+4]\n",
      "100%|██████████| 10/10 [01:00<00:00,  6.03s/it, loss=-1.33e+4]\n",
      "100%|██████████| 10/10 [00:59<00:00,  5.98s/it, loss=-1.04e+4]\n",
      "100%|██████████| 10/10 [01:00<00:00,  6.00s/it, loss=-1.35e+4]\n",
      "100%|██████████| 10/10 [00:59<00:00,  5.96s/it, loss=-1.45e+4]\n",
      "100%|██████████| 10/10 [01:00<00:00,  6.01s/it, loss=-9.72e+3]\n",
      "100%|██████████| 10/10 [00:59<00:00,  5.98s/it, loss=-1.38e+4]\n",
      "100%|██████████| 10/10 [00:59<00:00,  5.98s/it, loss=-1.36e+4]\n",
      "100%|██████████| 10/10 [00:59<00:00,  5.94s/it, loss=-1.37e+4]\n",
      "100%|██████████| 10/10 [01:00<00:00,  6.02s/it, loss=-1.31e+4]\n",
      "100%|██████████| 10/10 [01:00<00:00,  6.01s/it, loss=-1.25e+4]\n",
      "100%|██████████| 10/10 [00:59<00:00,  5.97s/it, loss=-1.31e+4]\n",
      "100%|██████████| 10/10 [00:59<00:00,  5.94s/it, loss=-1.54e+4]\n",
      "100%|██████████| 10/10 [01:00<00:00,  6.04s/it, loss=-1.5e+4]\n",
      "100%|██████████| 10/10 [00:59<00:00,  5.99s/it, loss=-1.26e+4]\n",
      "100%|██████████| 10/10 [01:00<00:00,  6.03s/it, loss=-1.57e+4]\n",
      "100%|██████████| 10/10 [00:59<00:00,  5.98s/it, loss=-1.61e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n",
      "Accuracy: 0.60%, Dice Score: 1.9994\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
